---
title: "Supervised Machine Learning for Text Analysis in R"
author: Julia Silge
date: '2020-07-24'
slug: smltar-announce
categories:
  - rstats
tags:
  - rstats
subtitle: ''
summary: "Announcing our new book, to be published in the Chapman & Hall/CRC Data Science Series!"
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: true
projects: []
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(cache = TRUE, warning = FALSE, message = FALSE, 
                      echo = TRUE, dpi = 300, cache.lazy = FALSE,
                      tidy = "styler", fig.width = 8, fig.height = 5)
options(cli.width = 70, width = 70)
library(scales)
library(tidyverse)
library(silgelib)
theme_set(theme_plex())
```

Today, [Emil Hvitfeldt](https://www.hvitfeldt.me/) and I led a [useR! 2020](https://user2020.r-project.org/) online tutorial on predicted modeling with text using tidy data principles. This tutorial was hosted by [R-Ladies en Argentina](https://github.com/RLadiesEnArgentina/user2020tutorial); huge thanks to the organizers for their leadership and effort in making this tutorial possible.

![tutorial flyer](featured.png)

Materials for this tutorial are [available on GitHub](https://github.com/EmilHvitfeldt/useR2020-text-modeling-tutorial), with two main resources in the repo:

- Slides, which you can [see rendered here](https://emilhvitfeldt.github.io/useR2020-text-modeling-tutorial/) and the [source for here](https://github.com/EmilHvitfeldt/useR2020-text-modeling-tutorial/blob/master/index.Rmd)
- An [R Markdown file to work through](https://github.com/EmilHvitfeldt/useR2020-text-modeling-tutorial/blob/master/text_modeling.Rmd)

If you start working through these materials and get stuck, you can [post on RStudio Community](https://rstd.io/tidymodels-community) or [post a question as an issue on the repo](https://github.com/EmilHvitfeldt/useR2020-text-modeling-tutorial/issues). Our goal in designing this tutorial was to create resources for async learning.

The content for this tutorial is largely based on a new project that Emil and I are working on, which we are thrilled to publicly announce as of today: our book [_Supervised Machine Learning for Text Analysis in R_](https://smltar.com/) to be published in the Chapman & Hall/CRC Data Science Series!

![oh yeah](https://media.giphy.com/media/HBblEmWutaXQY/giphy.gif)

That title is a bit of a mouthful, so we like to call our project **SMLTAR**, which is also the [URL](https://smltar.com/) where you can and will always be able to find the online version of this book. We invite you to take a look at the work we've done already, and explore how unstructured text data can be used for supervised predictive models. The book is divided into three sections.

- **Natural language features:** How do we transform text data into a representation useful for modeling? In these chapters, we explore the most common preprocessing steps for text, when they are helpful, and when they are not. This section is in good shape already!

- **Machine learning methods:** We investigate the power of some of the simpler and more lightweight models in our toolbox. We drew from these chapters in our [useR tutorial](https://github.com/EmilHvitfeldt/useR2020-text-modeling-tutorial).

- **Deep learning methods:** Given more time and resources, we see what is possible once we turn to neural networks. This section is still to come.

Already, we have so many people to thank for their contributions and support, including our Chapman & Hall editor John Kimmel, the helpful technical reviewers, and Desir√©e De Leon for the site design of the book's website. We hope you get a chance to check out this project!


